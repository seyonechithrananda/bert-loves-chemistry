{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858d257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451562fc",
   "metadata": {},
   "source": [
    "Load in `.csv` file that came from `stage-p2x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a58b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('runs_with_eval_loss_and_params.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b4b4e8",
   "metadata": {},
   "source": [
    "Load in data from MolNet finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb4840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62eeae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fcdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb87946",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bucket = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af05648",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_dir = f's3://{model_bucket}/chemberta/mtr_pretraining_5M_20210804/molnet_mtr_5M_ft_20210804/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8096cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(cloud_dir):\n",
    "    run_dirs = fs.ls(cloud_dir)\n",
    "    data_avg = []\n",
    "    df_all = pd.DataFrame()\n",
    "    for rd in run_dirs:\n",
    "        run_name = os.path.basename(os.path.normpath(rd))\n",
    "        # go one level down to get the molnet task\n",
    "        molnet_task_data_avg = {}\n",
    "        molnet_task_data_all = {}\n",
    "        for molnet_task_dir in fs.ls(rd):\n",
    "            molnet_task_name = os.path.basename(os.path.normpath(molnet_task_dir))\n",
    "            results_dir = os.path.join(molnet_task_dir, \"results/\")\n",
    "            for subset in [\"valid\", \"test\"]:\n",
    "                with fs.open(os.path.join(results_dir, subset, \"metrics.json\")) as f:\n",
    "                    metrics = json.load(f)\n",
    "                # pick first item to get the keys\n",
    "                metric_names = list(list(metrics.items())[0][1].keys())\n",
    "                metric_res = {mn: [] for mn in metric_names}\n",
    "                for seed, res in metrics.items():\n",
    "                    for mn, mres in res.items():\n",
    "                        if mn == \"pearsonr\":\n",
    "                            metric_res[mn].append(mres[0])\n",
    "                        else:\n",
    "                            metric_res[mn].append(mres)\n",
    "                molnet_task_data_all.update({f\"{molnet_task_name}_{subset}_{mn}\": metric_res[mn] for mn in metric_names})\n",
    "                average_metrics = {f\"{molnet_task_name}_{subset}_{mn}_mean\": np.mean(metric_res[mn]) for mn in metric_names}\n",
    "                std_metrics = {f\"{molnet_task_name}_{subset}_{mn}_std\": np.std(metric_res[mn]) for mn in metric_names}\n",
    "                molnet_task_data_avg.update({**average_metrics, **std_metrics})\n",
    "        molnet_task_data_all.update({\"run_name\": [run_name]*5})\n",
    "        df_all = df_all.append(pd.DataFrame(molnet_task_data_all))\n",
    "        data_avg.append({\"run_name\": run_name, **molnet_task_data_avg})\n",
    "\n",
    "    df_avg = pd.DataFrame(data_avg)\n",
    "    return df_all, df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86dd736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all, df_avg = get_dataframes(cloud_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "091785bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bace_classification_valid_roc_auc_score</th>\n",
       "      <th>bace_classification_valid_average_precision_score</th>\n",
       "      <th>bace_classification_test_roc_auc_score</th>\n",
       "      <th>bace_classification_test_average_precision_score</th>\n",
       "      <th>bace_regression_valid_pearsonr</th>\n",
       "      <th>bace_regression_valid_rmse</th>\n",
       "      <th>bace_regression_test_pearsonr</th>\n",
       "      <th>bace_regression_test_rmse</th>\n",
       "      <th>bbbp_valid_roc_auc_score</th>\n",
       "      <th>bbbp_valid_average_precision_score</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_rmse</th>\n",
       "      <th>lipo_valid_pearsonr</th>\n",
       "      <th>lipo_valid_rmse</th>\n",
       "      <th>lipo_test_pearsonr</th>\n",
       "      <th>lipo_test_rmse</th>\n",
       "      <th>tox21_valid_roc_auc_score</th>\n",
       "      <th>tox21_valid_average_precision_score</th>\n",
       "      <th>tox21_test_roc_auc_score</th>\n",
       "      <th>tox21_test_average_precision_score</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596748</td>\n",
       "      <td>0.640503</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.803327</td>\n",
       "      <td>0.113098</td>\n",
       "      <td>0.494110</td>\n",
       "      <td>0.731038</td>\n",
       "      <td>1.096858</td>\n",
       "      <td>0.970303</td>\n",
       "      <td>0.968082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461782</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>0.648206</td>\n",
       "      <td>0.719486</td>\n",
       "      <td>0.641808</td>\n",
       "      <td>0.783030</td>\n",
       "      <td>0.453764</td>\n",
       "      <td>0.747493</td>\n",
       "      <td>0.424763</td>\n",
       "      <td>run_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.596482</td>\n",
       "      <td>0.640416</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.803327</td>\n",
       "      <td>0.113863</td>\n",
       "      <td>0.491202</td>\n",
       "      <td>0.729922</td>\n",
       "      <td>1.083382</td>\n",
       "      <td>0.969138</td>\n",
       "      <td>0.968365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461380</td>\n",
       "      <td>0.773772</td>\n",
       "      <td>0.647530</td>\n",
       "      <td>0.718227</td>\n",
       "      <td>0.642561</td>\n",
       "      <td>0.775867</td>\n",
       "      <td>0.447403</td>\n",
       "      <td>0.754734</td>\n",
       "      <td>0.429691</td>\n",
       "      <td>run_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596660</td>\n",
       "      <td>0.641714</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.803327</td>\n",
       "      <td>0.113995</td>\n",
       "      <td>0.495492</td>\n",
       "      <td>0.729105</td>\n",
       "      <td>1.098197</td>\n",
       "      <td>0.969332</td>\n",
       "      <td>0.967980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462781</td>\n",
       "      <td>0.761252</td>\n",
       "      <td>0.660363</td>\n",
       "      <td>0.704606</td>\n",
       "      <td>0.653160</td>\n",
       "      <td>0.781400</td>\n",
       "      <td>0.453767</td>\n",
       "      <td>0.741426</td>\n",
       "      <td>0.429049</td>\n",
       "      <td>run_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596482</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.803327</td>\n",
       "      <td>0.111739</td>\n",
       "      <td>0.494640</td>\n",
       "      <td>0.733085</td>\n",
       "      <td>1.097865</td>\n",
       "      <td>0.969429</td>\n",
       "      <td>0.967529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458823</td>\n",
       "      <td>0.753817</td>\n",
       "      <td>0.671968</td>\n",
       "      <td>0.695670</td>\n",
       "      <td>0.661683</td>\n",
       "      <td>0.778955</td>\n",
       "      <td>0.448230</td>\n",
       "      <td>0.747444</td>\n",
       "      <td>0.422272</td>\n",
       "      <td>run_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.596393</td>\n",
       "      <td>0.640210</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.803327</td>\n",
       "      <td>0.113524</td>\n",
       "      <td>0.492913</td>\n",
       "      <td>0.731399</td>\n",
       "      <td>1.095938</td>\n",
       "      <td>0.970982</td>\n",
       "      <td>0.970051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460283</td>\n",
       "      <td>0.780542</td>\n",
       "      <td>0.641785</td>\n",
       "      <td>0.724696</td>\n",
       "      <td>0.639564</td>\n",
       "      <td>0.777968</td>\n",
       "      <td>0.452808</td>\n",
       "      <td>0.744802</td>\n",
       "      <td>0.427032</td>\n",
       "      <td>run_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.650498</td>\n",
       "      <td>0.692315</td>\n",
       "      <td>0.791486</td>\n",
       "      <td>0.835834</td>\n",
       "      <td>0.172229</td>\n",
       "      <td>0.563354</td>\n",
       "      <td>0.799910</td>\n",
       "      <td>1.104355</td>\n",
       "      <td>0.967682</td>\n",
       "      <td>0.968240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410833</td>\n",
       "      <td>0.699566</td>\n",
       "      <td>0.731749</td>\n",
       "      <td>0.661364</td>\n",
       "      <td>0.707962</td>\n",
       "      <td>0.763856</td>\n",
       "      <td>0.456702</td>\n",
       "      <td>0.831450</td>\n",
       "      <td>0.420656</td>\n",
       "      <td>run_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649076</td>\n",
       "      <td>0.690954</td>\n",
       "      <td>0.791486</td>\n",
       "      <td>0.831017</td>\n",
       "      <td>0.182468</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>0.810622</td>\n",
       "      <td>1.001958</td>\n",
       "      <td>0.968071</td>\n",
       "      <td>0.969398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414782</td>\n",
       "      <td>0.707672</td>\n",
       "      <td>0.722468</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.701355</td>\n",
       "      <td>0.771706</td>\n",
       "      <td>0.465950</td>\n",
       "      <td>0.803219</td>\n",
       "      <td>0.397695</td>\n",
       "      <td>run_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.651208</td>\n",
       "      <td>0.692552</td>\n",
       "      <td>0.791123</td>\n",
       "      <td>0.835047</td>\n",
       "      <td>0.167925</td>\n",
       "      <td>0.560005</td>\n",
       "      <td>0.803815</td>\n",
       "      <td>1.089828</td>\n",
       "      <td>0.967974</td>\n",
       "      <td>0.969196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429092</td>\n",
       "      <td>0.702438</td>\n",
       "      <td>0.722310</td>\n",
       "      <td>0.637848</td>\n",
       "      <td>0.722440</td>\n",
       "      <td>0.765743</td>\n",
       "      <td>0.463505</td>\n",
       "      <td>0.821273</td>\n",
       "      <td>0.406365</td>\n",
       "      <td>run_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.652097</td>\n",
       "      <td>0.690869</td>\n",
       "      <td>0.790399</td>\n",
       "      <td>0.831698</td>\n",
       "      <td>0.164164</td>\n",
       "      <td>0.565016</td>\n",
       "      <td>0.793742</td>\n",
       "      <td>1.118970</td>\n",
       "      <td>0.968071</td>\n",
       "      <td>0.969543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418384</td>\n",
       "      <td>0.702826</td>\n",
       "      <td>0.727075</td>\n",
       "      <td>0.660596</td>\n",
       "      <td>0.707792</td>\n",
       "      <td>0.780585</td>\n",
       "      <td>0.456097</td>\n",
       "      <td>0.806546</td>\n",
       "      <td>0.396876</td>\n",
       "      <td>run_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.698773</td>\n",
       "      <td>0.796377</td>\n",
       "      <td>0.840267</td>\n",
       "      <td>0.177277</td>\n",
       "      <td>0.564676</td>\n",
       "      <td>0.808512</td>\n",
       "      <td>1.065302</td>\n",
       "      <td>0.968459</td>\n",
       "      <td>0.969447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423083</td>\n",
       "      <td>0.691847</td>\n",
       "      <td>0.736963</td>\n",
       "      <td>0.636978</td>\n",
       "      <td>0.729956</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.822692</td>\n",
       "      <td>0.422046</td>\n",
       "      <td>run_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.529673</td>\n",
       "      <td>0.583953</td>\n",
       "      <td>0.697283</td>\n",
       "      <td>0.709290</td>\n",
       "      <td>0.161349</td>\n",
       "      <td>0.603556</td>\n",
       "      <td>0.790651</td>\n",
       "      <td>1.241379</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.967364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528923</td>\n",
       "      <td>0.634540</td>\n",
       "      <td>0.784420</td>\n",
       "      <td>0.579986</td>\n",
       "      <td>0.773747</td>\n",
       "      <td>0.733957</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.832575</td>\n",
       "      <td>0.453835</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529495</td>\n",
       "      <td>0.583881</td>\n",
       "      <td>0.696920</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.163660</td>\n",
       "      <td>0.602952</td>\n",
       "      <td>0.789904</td>\n",
       "      <td>1.242100</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.973040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498627</td>\n",
       "      <td>0.636754</td>\n",
       "      <td>0.786828</td>\n",
       "      <td>0.587681</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.747769</td>\n",
       "      <td>0.444448</td>\n",
       "      <td>0.827585</td>\n",
       "      <td>0.446260</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529495</td>\n",
       "      <td>0.583881</td>\n",
       "      <td>0.696920</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.158010</td>\n",
       "      <td>0.603545</td>\n",
       "      <td>0.783566</td>\n",
       "      <td>1.246452</td>\n",
       "      <td>0.965256</td>\n",
       "      <td>0.970781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496694</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.785002</td>\n",
       "      <td>0.583220</td>\n",
       "      <td>0.766603</td>\n",
       "      <td>0.756949</td>\n",
       "      <td>0.444470</td>\n",
       "      <td>0.829101</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529673</td>\n",
       "      <td>0.583953</td>\n",
       "      <td>0.697101</td>\n",
       "      <td>0.709147</td>\n",
       "      <td>0.161608</td>\n",
       "      <td>0.602998</td>\n",
       "      <td>0.789940</td>\n",
       "      <td>1.241596</td>\n",
       "      <td>0.964383</td>\n",
       "      <td>0.968444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542233</td>\n",
       "      <td>0.633254</td>\n",
       "      <td>0.785299</td>\n",
       "      <td>0.584492</td>\n",
       "      <td>0.768678</td>\n",
       "      <td>0.753089</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.834287</td>\n",
       "      <td>0.436694</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.529318</td>\n",
       "      <td>0.583799</td>\n",
       "      <td>0.696920</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.160518</td>\n",
       "      <td>0.603003</td>\n",
       "      <td>0.784731</td>\n",
       "      <td>1.245802</td>\n",
       "      <td>0.962733</td>\n",
       "      <td>0.968183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532144</td>\n",
       "      <td>0.632086</td>\n",
       "      <td>0.787740</td>\n",
       "      <td>0.582310</td>\n",
       "      <td>0.772713</td>\n",
       "      <td>0.747383</td>\n",
       "      <td>0.454678</td>\n",
       "      <td>0.833798</td>\n",
       "      <td>0.459664</td>\n",
       "      <td>run_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.616205</td>\n",
       "      <td>0.688194</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.812104</td>\n",
       "      <td>0.134182</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.754478</td>\n",
       "      <td>1.099738</td>\n",
       "      <td>0.960695</td>\n",
       "      <td>0.963132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473826</td>\n",
       "      <td>0.585601</td>\n",
       "      <td>0.815095</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.778248</td>\n",
       "      <td>0.761110</td>\n",
       "      <td>0.474264</td>\n",
       "      <td>0.804981</td>\n",
       "      <td>0.342878</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.618870</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.781159</td>\n",
       "      <td>0.813322</td>\n",
       "      <td>0.129855</td>\n",
       "      <td>0.549372</td>\n",
       "      <td>0.757689</td>\n",
       "      <td>1.078783</td>\n",
       "      <td>0.958366</td>\n",
       "      <td>0.965304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464875</td>\n",
       "      <td>0.595695</td>\n",
       "      <td>0.808738</td>\n",
       "      <td>0.558163</td>\n",
       "      <td>0.762622</td>\n",
       "      <td>0.754290</td>\n",
       "      <td>0.447144</td>\n",
       "      <td>0.799795</td>\n",
       "      <td>0.345286</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.615849</td>\n",
       "      <td>0.686704</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.813293</td>\n",
       "      <td>0.133898</td>\n",
       "      <td>0.552339</td>\n",
       "      <td>0.751822</td>\n",
       "      <td>1.104303</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.965504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462572</td>\n",
       "      <td>0.599250</td>\n",
       "      <td>0.806847</td>\n",
       "      <td>0.558706</td>\n",
       "      <td>0.763863</td>\n",
       "      <td>0.744852</td>\n",
       "      <td>0.454886</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>0.371321</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.702671</td>\n",
       "      <td>0.786051</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.134129</td>\n",
       "      <td>0.548361</td>\n",
       "      <td>0.753503</td>\n",
       "      <td>1.102714</td>\n",
       "      <td>0.956036</td>\n",
       "      <td>0.956895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460415</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.809195</td>\n",
       "      <td>0.557109</td>\n",
       "      <td>0.765294</td>\n",
       "      <td>0.758880</td>\n",
       "      <td>0.468519</td>\n",
       "      <td>0.803660</td>\n",
       "      <td>0.351421</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.614783</td>\n",
       "      <td>0.689249</td>\n",
       "      <td>0.782065</td>\n",
       "      <td>0.813585</td>\n",
       "      <td>0.137336</td>\n",
       "      <td>0.551788</td>\n",
       "      <td>0.750404</td>\n",
       "      <td>1.117618</td>\n",
       "      <td>0.959724</td>\n",
       "      <td>0.962685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.592402</td>\n",
       "      <td>0.810230</td>\n",
       "      <td>0.543326</td>\n",
       "      <td>0.774747</td>\n",
       "      <td>0.759695</td>\n",
       "      <td>0.478129</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>0.356120</td>\n",
       "      <td>run_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586709</td>\n",
       "      <td>0.651026</td>\n",
       "      <td>0.735507</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.204913</td>\n",
       "      <td>0.495708</td>\n",
       "      <td>0.715241</td>\n",
       "      <td>1.087945</td>\n",
       "      <td>0.965062</td>\n",
       "      <td>0.958918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467214</td>\n",
       "      <td>0.825732</td>\n",
       "      <td>0.580878</td>\n",
       "      <td>0.781855</td>\n",
       "      <td>0.593911</td>\n",
       "      <td>0.767159</td>\n",
       "      <td>0.469941</td>\n",
       "      <td>0.743676</td>\n",
       "      <td>0.366079</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.587242</td>\n",
       "      <td>0.651885</td>\n",
       "      <td>0.735688</td>\n",
       "      <td>0.811010</td>\n",
       "      <td>0.205093</td>\n",
       "      <td>0.495571</td>\n",
       "      <td>0.714707</td>\n",
       "      <td>1.087547</td>\n",
       "      <td>0.965936</td>\n",
       "      <td>0.959717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468242</td>\n",
       "      <td>0.821326</td>\n",
       "      <td>0.587974</td>\n",
       "      <td>0.778362</td>\n",
       "      <td>0.596874</td>\n",
       "      <td>0.768531</td>\n",
       "      <td>0.469811</td>\n",
       "      <td>0.741621</td>\n",
       "      <td>0.362950</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587065</td>\n",
       "      <td>0.651598</td>\n",
       "      <td>0.735507</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.205240</td>\n",
       "      <td>0.494638</td>\n",
       "      <td>0.715837</td>\n",
       "      <td>1.086867</td>\n",
       "      <td>0.964771</td>\n",
       "      <td>0.957545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460513</td>\n",
       "      <td>0.824972</td>\n",
       "      <td>0.582189</td>\n",
       "      <td>0.778968</td>\n",
       "      <td>0.595169</td>\n",
       "      <td>0.773207</td>\n",
       "      <td>0.471116</td>\n",
       "      <td>0.736044</td>\n",
       "      <td>0.362609</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.586887</td>\n",
       "      <td>0.651402</td>\n",
       "      <td>0.735507</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.205007</td>\n",
       "      <td>0.495099</td>\n",
       "      <td>0.715489</td>\n",
       "      <td>1.087173</td>\n",
       "      <td>0.964383</td>\n",
       "      <td>0.957360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457908</td>\n",
       "      <td>0.822790</td>\n",
       "      <td>0.586048</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.590521</td>\n",
       "      <td>0.765228</td>\n",
       "      <td>0.465970</td>\n",
       "      <td>0.745731</td>\n",
       "      <td>0.364489</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.586887</td>\n",
       "      <td>0.651402</td>\n",
       "      <td>0.735507</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.204843</td>\n",
       "      <td>0.495205</td>\n",
       "      <td>0.715085</td>\n",
       "      <td>1.090039</td>\n",
       "      <td>0.965547</td>\n",
       "      <td>0.959035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469629</td>\n",
       "      <td>0.824558</td>\n",
       "      <td>0.585865</td>\n",
       "      <td>0.781918</td>\n",
       "      <td>0.590748</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.472628</td>\n",
       "      <td>0.735114</td>\n",
       "      <td>0.359081</td>\n",
       "      <td>run_45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bace_classification_valid_roc_auc_score  \\\n",
       "0                                 0.596748   \n",
       "1                                 0.596482   \n",
       "2                                 0.596660   \n",
       "3                                 0.596482   \n",
       "4                                 0.596393   \n",
       "0                                 0.650498   \n",
       "1                                 0.649076   \n",
       "2                                 0.651208   \n",
       "3                                 0.652097   \n",
       "4                                 0.656716   \n",
       "0                                 0.529673   \n",
       "1                                 0.529495   \n",
       "2                                 0.529495   \n",
       "3                                 0.529673   \n",
       "4                                 0.529318   \n",
       "0                                 0.616205   \n",
       "1                                 0.618870   \n",
       "2                                 0.615849   \n",
       "3                                 0.625800   \n",
       "4                                 0.614783   \n",
       "0                                 0.586709   \n",
       "1                                 0.587242   \n",
       "2                                 0.587065   \n",
       "3                                 0.586887   \n",
       "4                                 0.586887   \n",
       "\n",
       "   bace_classification_valid_average_precision_score  \\\n",
       "0                                           0.640503   \n",
       "1                                           0.640416   \n",
       "2                                           0.641714   \n",
       "3                                           0.640297   \n",
       "4                                           0.640210   \n",
       "0                                           0.692315   \n",
       "1                                           0.690954   \n",
       "2                                           0.692552   \n",
       "3                                           0.690869   \n",
       "4                                           0.698773   \n",
       "0                                           0.583953   \n",
       "1                                           0.583881   \n",
       "2                                           0.583881   \n",
       "3                                           0.583953   \n",
       "4                                           0.583799   \n",
       "0                                           0.688194   \n",
       "1                                           0.691667   \n",
       "2                                           0.686704   \n",
       "3                                           0.702671   \n",
       "4                                           0.689249   \n",
       "0                                           0.651026   \n",
       "1                                           0.651885   \n",
       "2                                           0.651598   \n",
       "3                                           0.651402   \n",
       "4                                           0.651402   \n",
       "\n",
       "   bace_classification_test_roc_auc_score  \\\n",
       "0                                0.757428   \n",
       "1                                0.757428   \n",
       "2                                0.757428   \n",
       "3                                0.757428   \n",
       "4                                0.757428   \n",
       "0                                0.791486   \n",
       "1                                0.791486   \n",
       "2                                0.791123   \n",
       "3                                0.790399   \n",
       "4                                0.796377   \n",
       "0                                0.697283   \n",
       "1                                0.696920   \n",
       "2                                0.696920   \n",
       "3                                0.697101   \n",
       "4                                0.696920   \n",
       "0                                0.779167   \n",
       "1                                0.781159   \n",
       "2                                0.781703   \n",
       "3                                0.786051   \n",
       "4                                0.782065   \n",
       "0                                0.735507   \n",
       "1                                0.735688   \n",
       "2                                0.735507   \n",
       "3                                0.735507   \n",
       "4                                0.735507   \n",
       "\n",
       "   bace_classification_test_average_precision_score  \\\n",
       "0                                          0.803327   \n",
       "1                                          0.803327   \n",
       "2                                          0.803327   \n",
       "3                                          0.803327   \n",
       "4                                          0.803327   \n",
       "0                                          0.835834   \n",
       "1                                          0.831017   \n",
       "2                                          0.835047   \n",
       "3                                          0.831698   \n",
       "4                                          0.840267   \n",
       "0                                          0.709290   \n",
       "1                                          0.709063   \n",
       "2                                          0.709063   \n",
       "3                                          0.709147   \n",
       "4                                          0.709063   \n",
       "0                                          0.812104   \n",
       "1                                          0.813322   \n",
       "2                                          0.813293   \n",
       "3                                          0.813542   \n",
       "4                                          0.813585   \n",
       "0                                          0.810948   \n",
       "1                                          0.811010   \n",
       "2                                          0.810948   \n",
       "3                                          0.810948   \n",
       "4                                          0.810948   \n",
       "\n",
       "   bace_regression_valid_pearsonr  bace_regression_valid_rmse  \\\n",
       "0                        0.113098                    0.494110   \n",
       "1                        0.113863                    0.491202   \n",
       "2                        0.113995                    0.495492   \n",
       "3                        0.111739                    0.494640   \n",
       "4                        0.113524                    0.492913   \n",
       "0                        0.172229                    0.563354   \n",
       "1                        0.182468                    0.565476   \n",
       "2                        0.167925                    0.560005   \n",
       "3                        0.164164                    0.565016   \n",
       "4                        0.177277                    0.564676   \n",
       "0                        0.161349                    0.603556   \n",
       "1                        0.163660                    0.602952   \n",
       "2                        0.158010                    0.603545   \n",
       "3                        0.161608                    0.602998   \n",
       "4                        0.160518                    0.603003   \n",
       "0                        0.134182                    0.548300   \n",
       "1                        0.129855                    0.549372   \n",
       "2                        0.133898                    0.552339   \n",
       "3                        0.134129                    0.548361   \n",
       "4                        0.137336                    0.551788   \n",
       "0                        0.204913                    0.495708   \n",
       "1                        0.205093                    0.495571   \n",
       "2                        0.205240                    0.494638   \n",
       "3                        0.205007                    0.495099   \n",
       "4                        0.204843                    0.495205   \n",
       "\n",
       "   bace_regression_test_pearsonr  bace_regression_test_rmse  \\\n",
       "0                       0.731038                   1.096858   \n",
       "1                       0.729922                   1.083382   \n",
       "2                       0.729105                   1.098197   \n",
       "3                       0.733085                   1.097865   \n",
       "4                       0.731399                   1.095938   \n",
       "0                       0.799910                   1.104355   \n",
       "1                       0.810622                   1.001958   \n",
       "2                       0.803815                   1.089828   \n",
       "3                       0.793742                   1.118970   \n",
       "4                       0.808512                   1.065302   \n",
       "0                       0.790651                   1.241379   \n",
       "1                       0.789904                   1.242100   \n",
       "2                       0.783566                   1.246452   \n",
       "3                       0.789940                   1.241596   \n",
       "4                       0.784731                   1.245802   \n",
       "0                       0.754478                   1.099738   \n",
       "1                       0.757689                   1.078783   \n",
       "2                       0.751822                   1.104303   \n",
       "3                       0.753503                   1.102714   \n",
       "4                       0.750404                   1.117618   \n",
       "0                       0.715241                   1.087945   \n",
       "1                       0.714707                   1.087547   \n",
       "2                       0.715837                   1.086867   \n",
       "3                       0.715489                   1.087173   \n",
       "4                       0.715085                   1.090039   \n",
       "\n",
       "   bbbp_valid_roc_auc_score  bbbp_valid_average_precision_score  ...  \\\n",
       "0                  0.970303                            0.968082  ...   \n",
       "1                  0.969138                            0.968365  ...   \n",
       "2                  0.969332                            0.967980  ...   \n",
       "3                  0.969429                            0.967529  ...   \n",
       "4                  0.970982                            0.970051  ...   \n",
       "0                  0.967682                            0.968240  ...   \n",
       "1                  0.968071                            0.969398  ...   \n",
       "2                  0.967974                            0.969196  ...   \n",
       "3                  0.968071                            0.969543  ...   \n",
       "4                  0.968459                            0.969447  ...   \n",
       "0                  0.962733                            0.967364  ...   \n",
       "1                  0.967585                            0.973040  ...   \n",
       "2                  0.965256                            0.970781  ...   \n",
       "3                  0.964383                            0.968444  ...   \n",
       "4                  0.962733                            0.968183  ...   \n",
       "0                  0.960695                            0.963132  ...   \n",
       "1                  0.958366                            0.965304  ...   \n",
       "2                  0.959239                            0.965504  ...   \n",
       "3                  0.956036                            0.956895  ...   \n",
       "4                  0.959724                            0.962685  ...   \n",
       "0                  0.965062                            0.958918  ...   \n",
       "1                  0.965936                            0.959717  ...   \n",
       "2                  0.964771                            0.957545  ...   \n",
       "3                  0.964383                            0.957360  ...   \n",
       "4                  0.965547                            0.959035  ...   \n",
       "\n",
       "   delaney_test_rmse  lipo_valid_pearsonr  lipo_valid_rmse  \\\n",
       "0           0.461782             0.773668         0.648206   \n",
       "1           0.461380             0.773772         0.647530   \n",
       "2           0.462781             0.761252         0.660363   \n",
       "3           0.458823             0.753817         0.671968   \n",
       "4           0.460283             0.780542         0.641785   \n",
       "0           0.410833             0.699566         0.731749   \n",
       "1           0.414782             0.707672         0.722468   \n",
       "2           0.429092             0.702438         0.722310   \n",
       "3           0.418384             0.702826         0.727075   \n",
       "4           0.423083             0.691847         0.736963   \n",
       "0           0.528923             0.634540         0.784420   \n",
       "1           0.498627             0.636754         0.786828   \n",
       "2           0.496694             0.631261         0.785002   \n",
       "3           0.542233             0.633254         0.785299   \n",
       "4           0.532144             0.632086         0.787740   \n",
       "0           0.473826             0.585601         0.815095   \n",
       "1           0.464875             0.595695         0.808738   \n",
       "2           0.462572             0.599250         0.806847   \n",
       "3           0.460415             0.595595         0.809195   \n",
       "4           0.461996             0.592402         0.810230   \n",
       "0           0.467214             0.825732         0.580878   \n",
       "1           0.468242             0.821326         0.587974   \n",
       "2           0.460513             0.824972         0.582189   \n",
       "3           0.457908             0.822790         0.586048   \n",
       "4           0.469629             0.824558         0.585865   \n",
       "\n",
       "   lipo_test_pearsonr  lipo_test_rmse  tox21_valid_roc_auc_score  \\\n",
       "0            0.719486        0.641808                   0.783030   \n",
       "1            0.718227        0.642561                   0.775867   \n",
       "2            0.704606        0.653160                   0.781400   \n",
       "3            0.695670        0.661683                   0.778955   \n",
       "4            0.724696        0.639564                   0.777968   \n",
       "0            0.661364        0.707962                   0.763856   \n",
       "1            0.665169        0.701355                   0.771706   \n",
       "2            0.637848        0.722440                   0.765743   \n",
       "3            0.660596        0.707792                   0.780585   \n",
       "4            0.636978        0.729956                   0.773550   \n",
       "0            0.579986        0.773747                   0.733957   \n",
       "1            0.587681        0.771717                   0.747769   \n",
       "2            0.583220        0.766603                   0.756949   \n",
       "3            0.584492        0.768678                   0.753089   \n",
       "4            0.582310        0.772713                   0.747383   \n",
       "0            0.538424        0.778248                   0.761110   \n",
       "1            0.558163        0.762622                   0.754290   \n",
       "2            0.558706        0.763863                   0.744852   \n",
       "3            0.557109        0.765294                   0.758880   \n",
       "4            0.543326        0.774747                   0.759695   \n",
       "0            0.781855        0.593911                   0.767159   \n",
       "1            0.778362        0.596874                   0.768531   \n",
       "2            0.778968        0.595169                   0.773207   \n",
       "3            0.782333        0.590521                   0.765228   \n",
       "4            0.781918        0.590748                   0.766386   \n",
       "\n",
       "   tox21_valid_average_precision_score  tox21_test_roc_auc_score  \\\n",
       "0                             0.453764                  0.747493   \n",
       "1                             0.447403                  0.754734   \n",
       "2                             0.453767                  0.741426   \n",
       "3                             0.448230                  0.747444   \n",
       "4                             0.452808                  0.744802   \n",
       "0                             0.456702                  0.831450   \n",
       "1                             0.465950                  0.803219   \n",
       "2                             0.463505                  0.821273   \n",
       "3                             0.456097                  0.806546   \n",
       "4                             0.463900                  0.822692   \n",
       "0                             0.428805                  0.832575   \n",
       "1                             0.444448                  0.827585   \n",
       "2                             0.444470                  0.829101   \n",
       "3                             0.457547                  0.834287   \n",
       "4                             0.454678                  0.833798   \n",
       "0                             0.474264                  0.804981   \n",
       "1                             0.447144                  0.799795   \n",
       "2                             0.454886                  0.822888   \n",
       "3                             0.468519                  0.803660   \n",
       "4                             0.478129                  0.792749   \n",
       "0                             0.469941                  0.743676   \n",
       "1                             0.469811                  0.741621   \n",
       "2                             0.471116                  0.736044   \n",
       "3                             0.465970                  0.745731   \n",
       "4                             0.472628                  0.735114   \n",
       "\n",
       "   tox21_test_average_precision_score  run_name  \n",
       "0                            0.424763     run_0  \n",
       "1                            0.429691     run_0  \n",
       "2                            0.429049     run_0  \n",
       "3                            0.422272     run_0  \n",
       "4                            0.427032     run_0  \n",
       "0                            0.420656     run_1  \n",
       "1                            0.397695     run_1  \n",
       "2                            0.406365     run_1  \n",
       "3                            0.396876     run_1  \n",
       "4                            0.422046     run_1  \n",
       "0                            0.453835    run_38  \n",
       "1                            0.446260    run_38  \n",
       "2                            0.453295    run_38  \n",
       "3                            0.436694    run_38  \n",
       "4                            0.459664    run_38  \n",
       "0                            0.342878    run_39  \n",
       "1                            0.345286    run_39  \n",
       "2                            0.371321    run_39  \n",
       "3                            0.351421    run_39  \n",
       "4                            0.356120    run_39  \n",
       "0                            0.366079    run_45  \n",
       "1                            0.362950    run_45  \n",
       "2                            0.362609    run_45  \n",
       "3                            0.364489    run_45  \n",
       "4                            0.359081    run_45  \n",
       "\n",
       "[25 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fc95fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>bace_classification_valid_roc_auc_score_mean</th>\n",
       "      <th>bace_classification_valid_average_precision_score_mean</th>\n",
       "      <th>bace_classification_valid_roc_auc_score_std</th>\n",
       "      <th>bace_classification_valid_average_precision_score_std</th>\n",
       "      <th>bace_classification_test_roc_auc_score_mean</th>\n",
       "      <th>bace_classification_test_average_precision_score_mean</th>\n",
       "      <th>bace_classification_test_roc_auc_score_std</th>\n",
       "      <th>bace_classification_test_average_precision_score_std</th>\n",
       "      <th>bace_regression_valid_pearsonr_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>lipo_test_pearsonr_std</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_std</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.596553</td>\n",
       "      <td>0.640628</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.757428</td>\n",
       "      <td>0.803327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010732</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.451194</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.747179</td>\n",
       "      <td>0.426561</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.002751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.651919</td>\n",
       "      <td>0.693092</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.792174</td>\n",
       "      <td>0.834773</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.172812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.771088</td>\n",
       "      <td>0.461231</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.817036</td>\n",
       "      <td>0.408728</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.010839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.529531</td>\n",
       "      <td>0.583894</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.697029</td>\n",
       "      <td>0.709125</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.161029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.747829</td>\n",
       "      <td>0.445990</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.449950</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.618301</td>\n",
       "      <td>0.691697</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.782029</td>\n",
       "      <td>0.813169</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.133880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.755765</td>\n",
       "      <td>0.464589</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.353405</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.010090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.586958</td>\n",
       "      <td>0.651463</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.735543</td>\n",
       "      <td>0.810961</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.205019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.768102</td>\n",
       "      <td>0.469893</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.740437</td>\n",
       "      <td>0.363042</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  bace_classification_valid_roc_auc_score_mean  \\\n",
       "0    run_0                                      0.596553   \n",
       "1    run_1                                      0.651919   \n",
       "2   run_38                                      0.529531   \n",
       "3   run_39                                      0.618301   \n",
       "4   run_45                                      0.586958   \n",
       "\n",
       "   bace_classification_valid_average_precision_score_mean  \\\n",
       "0                                           0.640628        \n",
       "1                                           0.693092        \n",
       "2                                           0.583894        \n",
       "3                                           0.691697        \n",
       "4                                           0.651463        \n",
       "\n",
       "   bace_classification_valid_roc_auc_score_std  \\\n",
       "0                                     0.000131   \n",
       "1                                     0.002594   \n",
       "2                                     0.000133   \n",
       "3                                     0.003983   \n",
       "4                                     0.000181   \n",
       "\n",
       "   bace_classification_valid_average_precision_score_std  \\\n",
       "0                                           0.000552       \n",
       "1                                           0.002922       \n",
       "2                                           0.000057       \n",
       "3                                           0.005720       \n",
       "4                                           0.000281       \n",
       "\n",
       "   bace_classification_test_roc_auc_score_mean  \\\n",
       "0                                     0.757428   \n",
       "1                                     0.792174   \n",
       "2                                     0.697029   \n",
       "3                                     0.782029   \n",
       "4                                     0.735543   \n",
       "\n",
       "   bace_classification_test_average_precision_score_mean  \\\n",
       "0                                           0.803327       \n",
       "1                                           0.834773       \n",
       "2                                           0.709125       \n",
       "3                                           0.813169       \n",
       "4                                           0.810961       \n",
       "\n",
       "   bace_classification_test_roc_auc_score_std  \\\n",
       "0                                    0.000000   \n",
       "1                                    0.002139   \n",
       "2                                    0.000145   \n",
       "3                                    0.002246   \n",
       "4                                    0.000072   \n",
       "\n",
       "   bace_classification_test_average_precision_score_std  \\\n",
       "0                                           0.000000      \n",
       "1                                           0.003315      \n",
       "2                                           0.000088      \n",
       "3                                           0.000545      \n",
       "4                                           0.000025      \n",
       "\n",
       "   bace_regression_valid_pearsonr_mean  ...  lipo_test_pearsonr_std  \\\n",
       "0                             0.113244  ...                0.010732   \n",
       "1                             0.172812  ...                0.012330   \n",
       "2                             0.161029  ...                0.002542   \n",
       "3                             0.133880  ...                0.008544   \n",
       "4                             0.205019  ...                0.001670   \n",
       "\n",
       "   lipo_test_rmse_std  tox21_valid_roc_auc_score_mean  \\\n",
       "0            0.008398                        0.779444   \n",
       "1            0.010589                        0.771088   \n",
       "2            0.002655                        0.747829   \n",
       "3            0.006314                        0.755765   \n",
       "4            0.002481                        0.768102   \n",
       "\n",
       "   tox21_valid_average_precision_score_mean  tox21_valid_roc_auc_score_std  \\\n",
       "0                                  0.451194                       0.002526   \n",
       "1                                  0.461231                       0.005958   \n",
       "2                                  0.445990                       0.007791   \n",
       "3                                  0.464589                       0.005916   \n",
       "4                                  0.469893                       0.002769   \n",
       "\n",
       "   tox21_valid_average_precision_score_std  tox21_test_roc_auc_score_mean  \\\n",
       "0                                 0.002792                       0.747179   \n",
       "1                                 0.004036                       0.817036   \n",
       "2                                 0.010090                       0.831469   \n",
       "3                                 0.011755                       0.804814   \n",
       "4                                 0.002208                       0.740437   \n",
       "\n",
       "   tox21_test_average_precision_score_mean  tox21_test_roc_auc_score_std  \\\n",
       "0                                 0.426561                      0.004382   \n",
       "1                                 0.408728                      0.010570   \n",
       "2                                 0.449950                      0.002657   \n",
       "3                                 0.353405                      0.009988   \n",
       "4                                 0.363042                      0.004185   \n",
       "\n",
       "   tox21_test_average_precision_score_std  \n",
       "0                                0.002751  \n",
       "1                                0.010839  \n",
       "2                                0.007874  \n",
       "3                                0.010090  \n",
       "4                                0.002332  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16d1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_avg_df = pd.merge(left=df, right=df_avg, on='run_name')\n",
    "# combined_avg_df['run_name'] = combined_avg_df['run_name'].apply(lambda x: f\"mlm_{x}\")\n",
    "\n",
    "combined_all_df = pd.merge(left=df, right=df_all, on='run_name')\n",
    "# combined_all_df['run_name'] = combined_all_df['run_name'].apply(lambda x: f\"mlm_{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc660dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>lipo_test_pearsonr_std</th>\n",
       "      <th>lipo_test_rmse_std</th>\n",
       "      <th>tox21_valid_roc_auc_score_mean</th>\n",
       "      <th>tox21_valid_average_precision_score_mean</th>\n",
       "      <th>tox21_valid_roc_auc_score_std</th>\n",
       "      <th>tox21_valid_average_precision_score_std</th>\n",
       "      <th>tox21_test_roc_auc_score_mean</th>\n",
       "      <th>tox21_test_average_precision_score_mean</th>\n",
       "      <th>tox21_test_roc_auc_score_std</th>\n",
       "      <th>tox21_test_average_precision_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.408093</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.755765</td>\n",
       "      <td>0.464589</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.353405</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.010090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>407</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9044</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.771088</td>\n",
       "      <td>0.461231</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.817036</td>\n",
       "      <td>0.408728</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.010839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.768102</td>\n",
       "      <td>0.469893</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.740437</td>\n",
       "      <td>0.363042</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.747829</td>\n",
       "      <td>0.445990</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.010090</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.449950</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>264</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.122</td>\n",
       "      <td>4888</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010732</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.779444</td>\n",
       "      <td>0.451194</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.747179</td>\n",
       "      <td>0.426561</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.002751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0   run_39       0.408093          209                         0.176   \n",
       "1    run_1       0.253704          407                         0.156   \n",
       "2   run_45       0.062321          384                         0.109   \n",
       "3   run_38       0.316783          126                         0.109   \n",
       "4    run_0       0.082666          264                         0.224   \n",
       "\n",
       "   hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                0.128               3968                   11   \n",
       "1                0.295               9044                   11   \n",
       "2                0.144                464                   12   \n",
       "3                0.279                456                    3   \n",
       "4                0.122               4888                    8   \n",
       "\n",
       "   num_hidden_layers  learning_rate  per_device_train_batch_size  ...  \\\n",
       "0                  3       0.000002                           25  ...   \n",
       "1                  2       0.000005                           25  ...   \n",
       "2                  3       0.000141                           25  ...   \n",
       "3                  2       0.000021                           25  ...   \n",
       "4                  3       0.000396                           25  ...   \n",
       "\n",
       "  lipo_test_pearsonr_std  lipo_test_rmse_std  tox21_valid_roc_auc_score_mean  \\\n",
       "0               0.008544            0.006314                        0.755765   \n",
       "1               0.012330            0.010589                        0.771088   \n",
       "2               0.001670            0.002481                        0.768102   \n",
       "3               0.002542            0.002655                        0.747829   \n",
       "4               0.010732            0.008398                        0.779444   \n",
       "\n",
       "   tox21_valid_average_precision_score_mean  tox21_valid_roc_auc_score_std  \\\n",
       "0                                  0.464589                       0.005916   \n",
       "1                                  0.461231                       0.005958   \n",
       "2                                  0.469893                       0.002769   \n",
       "3                                  0.445990                       0.007791   \n",
       "4                                  0.451194                       0.002526   \n",
       "\n",
       "   tox21_valid_average_precision_score_std  tox21_test_roc_auc_score_mean  \\\n",
       "0                                 0.011755                       0.804814   \n",
       "1                                 0.004036                       0.817036   \n",
       "2                                 0.002208                       0.740437   \n",
       "3                                 0.010090                       0.831469   \n",
       "4                                 0.002792                       0.747179   \n",
       "\n",
       "   tox21_test_average_precision_score_mean  tox21_test_roc_auc_score_std  \\\n",
       "0                                 0.353405                      0.009988   \n",
       "1                                 0.408728                      0.010570   \n",
       "2                                 0.363042                      0.004185   \n",
       "3                                 0.449950                      0.002657   \n",
       "4                                 0.426561                      0.004382   \n",
       "\n",
       "   tox21_test_average_precision_score_std  \n",
       "0                                0.010090  \n",
       "1                                0.010839  \n",
       "2                                0.002332  \n",
       "3                                0.007874  \n",
       "4                                0.002751  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3df0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>min_eval_loss</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention_probs_dropout_prob</th>\n",
       "      <th>hidden_dropout_prob</th>\n",
       "      <th>intermediate_size</th>\n",
       "      <th>num_attention_heads</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>delaney_test_pearsonr</th>\n",
       "      <th>delaney_test_rmse</th>\n",
       "      <th>lipo_valid_pearsonr</th>\n",
       "      <th>lipo_valid_rmse</th>\n",
       "      <th>lipo_test_pearsonr</th>\n",
       "      <th>lipo_test_rmse</th>\n",
       "      <th>tox21_valid_roc_auc_score</th>\n",
       "      <th>tox21_valid_average_precision_score</th>\n",
       "      <th>tox21_test_roc_auc_score</th>\n",
       "      <th>tox21_test_average_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.408093</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887726</td>\n",
       "      <td>0.473826</td>\n",
       "      <td>0.585601</td>\n",
       "      <td>0.815095</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.778248</td>\n",
       "      <td>0.761110</td>\n",
       "      <td>0.474264</td>\n",
       "      <td>0.804981</td>\n",
       "      <td>0.342878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.408093</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894136</td>\n",
       "      <td>0.464875</td>\n",
       "      <td>0.595695</td>\n",
       "      <td>0.808738</td>\n",
       "      <td>0.558163</td>\n",
       "      <td>0.762622</td>\n",
       "      <td>0.754290</td>\n",
       "      <td>0.447144</td>\n",
       "      <td>0.799795</td>\n",
       "      <td>0.345286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.408093</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896134</td>\n",
       "      <td>0.462572</td>\n",
       "      <td>0.599250</td>\n",
       "      <td>0.806847</td>\n",
       "      <td>0.558706</td>\n",
       "      <td>0.763863</td>\n",
       "      <td>0.744852</td>\n",
       "      <td>0.454886</td>\n",
       "      <td>0.822888</td>\n",
       "      <td>0.371321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.408093</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894566</td>\n",
       "      <td>0.460415</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.809195</td>\n",
       "      <td>0.557109</td>\n",
       "      <td>0.765294</td>\n",
       "      <td>0.758880</td>\n",
       "      <td>0.468519</td>\n",
       "      <td>0.803660</td>\n",
       "      <td>0.351421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_39</td>\n",
       "      <td>0.408093</td>\n",
       "      <td>209</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.128</td>\n",
       "      <td>3968</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896773</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.592402</td>\n",
       "      <td>0.810230</td>\n",
       "      <td>0.543326</td>\n",
       "      <td>0.774747</td>\n",
       "      <td>0.759695</td>\n",
       "      <td>0.478129</td>\n",
       "      <td>0.792749</td>\n",
       "      <td>0.356120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>407</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9044</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923107</td>\n",
       "      <td>0.410833</td>\n",
       "      <td>0.699566</td>\n",
       "      <td>0.731749</td>\n",
       "      <td>0.661364</td>\n",
       "      <td>0.707962</td>\n",
       "      <td>0.763856</td>\n",
       "      <td>0.456702</td>\n",
       "      <td>0.831450</td>\n",
       "      <td>0.420656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>407</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9044</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921820</td>\n",
       "      <td>0.414782</td>\n",
       "      <td>0.707672</td>\n",
       "      <td>0.722468</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.701355</td>\n",
       "      <td>0.771706</td>\n",
       "      <td>0.465950</td>\n",
       "      <td>0.803219</td>\n",
       "      <td>0.397695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>407</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9044</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910316</td>\n",
       "      <td>0.429092</td>\n",
       "      <td>0.702438</td>\n",
       "      <td>0.722310</td>\n",
       "      <td>0.637848</td>\n",
       "      <td>0.722440</td>\n",
       "      <td>0.765743</td>\n",
       "      <td>0.463505</td>\n",
       "      <td>0.821273</td>\n",
       "      <td>0.406365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>407</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9044</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919305</td>\n",
       "      <td>0.418384</td>\n",
       "      <td>0.702826</td>\n",
       "      <td>0.727075</td>\n",
       "      <td>0.660596</td>\n",
       "      <td>0.707792</td>\n",
       "      <td>0.780585</td>\n",
       "      <td>0.456097</td>\n",
       "      <td>0.806546</td>\n",
       "      <td>0.396876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run_1</td>\n",
       "      <td>0.253704</td>\n",
       "      <td>407</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.295</td>\n",
       "      <td>9044</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914678</td>\n",
       "      <td>0.423083</td>\n",
       "      <td>0.691847</td>\n",
       "      <td>0.736963</td>\n",
       "      <td>0.636978</td>\n",
       "      <td>0.729956</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.822692</td>\n",
       "      <td>0.422046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898042</td>\n",
       "      <td>0.467214</td>\n",
       "      <td>0.825732</td>\n",
       "      <td>0.580878</td>\n",
       "      <td>0.781855</td>\n",
       "      <td>0.593911</td>\n",
       "      <td>0.767159</td>\n",
       "      <td>0.469941</td>\n",
       "      <td>0.743676</td>\n",
       "      <td>0.366079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897441</td>\n",
       "      <td>0.468242</td>\n",
       "      <td>0.821326</td>\n",
       "      <td>0.587974</td>\n",
       "      <td>0.778362</td>\n",
       "      <td>0.596874</td>\n",
       "      <td>0.768531</td>\n",
       "      <td>0.469811</td>\n",
       "      <td>0.741621</td>\n",
       "      <td>0.362950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900106</td>\n",
       "      <td>0.460513</td>\n",
       "      <td>0.824972</td>\n",
       "      <td>0.582189</td>\n",
       "      <td>0.778968</td>\n",
       "      <td>0.595169</td>\n",
       "      <td>0.773207</td>\n",
       "      <td>0.471116</td>\n",
       "      <td>0.736044</td>\n",
       "      <td>0.362609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901569</td>\n",
       "      <td>0.457908</td>\n",
       "      <td>0.822790</td>\n",
       "      <td>0.586048</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>0.590521</td>\n",
       "      <td>0.765228</td>\n",
       "      <td>0.465970</td>\n",
       "      <td>0.745731</td>\n",
       "      <td>0.364489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>run_45</td>\n",
       "      <td>0.062321</td>\n",
       "      <td>384</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.144</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893857</td>\n",
       "      <td>0.469629</td>\n",
       "      <td>0.824558</td>\n",
       "      <td>0.585865</td>\n",
       "      <td>0.781918</td>\n",
       "      <td>0.590748</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.472628</td>\n",
       "      <td>0.735114</td>\n",
       "      <td>0.359081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859287</td>\n",
       "      <td>0.528923</td>\n",
       "      <td>0.634540</td>\n",
       "      <td>0.784420</td>\n",
       "      <td>0.579986</td>\n",
       "      <td>0.773747</td>\n",
       "      <td>0.733957</td>\n",
       "      <td>0.428805</td>\n",
       "      <td>0.832575</td>\n",
       "      <td>0.453835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875391</td>\n",
       "      <td>0.498627</td>\n",
       "      <td>0.636754</td>\n",
       "      <td>0.786828</td>\n",
       "      <td>0.587681</td>\n",
       "      <td>0.771717</td>\n",
       "      <td>0.747769</td>\n",
       "      <td>0.444448</td>\n",
       "      <td>0.827585</td>\n",
       "      <td>0.446260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876358</td>\n",
       "      <td>0.496694</td>\n",
       "      <td>0.631261</td>\n",
       "      <td>0.785002</td>\n",
       "      <td>0.583220</td>\n",
       "      <td>0.766603</td>\n",
       "      <td>0.756949</td>\n",
       "      <td>0.444470</td>\n",
       "      <td>0.829101</td>\n",
       "      <td>0.453295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851422</td>\n",
       "      <td>0.542233</td>\n",
       "      <td>0.633254</td>\n",
       "      <td>0.785299</td>\n",
       "      <td>0.584492</td>\n",
       "      <td>0.768678</td>\n",
       "      <td>0.753089</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>0.834287</td>\n",
       "      <td>0.436694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>run_38</td>\n",
       "      <td>0.316783</td>\n",
       "      <td>126</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.279</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855497</td>\n",
       "      <td>0.532144</td>\n",
       "      <td>0.632086</td>\n",
       "      <td>0.787740</td>\n",
       "      <td>0.582310</td>\n",
       "      <td>0.772713</td>\n",
       "      <td>0.747383</td>\n",
       "      <td>0.454678</td>\n",
       "      <td>0.833798</td>\n",
       "      <td>0.459664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>264</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.122</td>\n",
       "      <td>4888</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894696</td>\n",
       "      <td>0.461782</td>\n",
       "      <td>0.773668</td>\n",
       "      <td>0.648206</td>\n",
       "      <td>0.719486</td>\n",
       "      <td>0.641808</td>\n",
       "      <td>0.783030</td>\n",
       "      <td>0.453764</td>\n",
       "      <td>0.747493</td>\n",
       "      <td>0.424763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>264</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.122</td>\n",
       "      <td>4888</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894705</td>\n",
       "      <td>0.461380</td>\n",
       "      <td>0.773772</td>\n",
       "      <td>0.647530</td>\n",
       "      <td>0.718227</td>\n",
       "      <td>0.642561</td>\n",
       "      <td>0.775867</td>\n",
       "      <td>0.447403</td>\n",
       "      <td>0.754734</td>\n",
       "      <td>0.429691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>264</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.122</td>\n",
       "      <td>4888</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894023</td>\n",
       "      <td>0.462781</td>\n",
       "      <td>0.761252</td>\n",
       "      <td>0.660363</td>\n",
       "      <td>0.704606</td>\n",
       "      <td>0.653160</td>\n",
       "      <td>0.781400</td>\n",
       "      <td>0.453767</td>\n",
       "      <td>0.741426</td>\n",
       "      <td>0.429049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>264</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.122</td>\n",
       "      <td>4888</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895669</td>\n",
       "      <td>0.458823</td>\n",
       "      <td>0.753817</td>\n",
       "      <td>0.671968</td>\n",
       "      <td>0.695670</td>\n",
       "      <td>0.661683</td>\n",
       "      <td>0.778955</td>\n",
       "      <td>0.448230</td>\n",
       "      <td>0.747444</td>\n",
       "      <td>0.422272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>run_0</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>264</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.122</td>\n",
       "      <td>4888</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895317</td>\n",
       "      <td>0.460283</td>\n",
       "      <td>0.780542</td>\n",
       "      <td>0.641785</td>\n",
       "      <td>0.724696</td>\n",
       "      <td>0.639564</td>\n",
       "      <td>0.777968</td>\n",
       "      <td>0.452808</td>\n",
       "      <td>0.744802</td>\n",
       "      <td>0.427032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_name  min_eval_loss  hidden_size  attention_probs_dropout_prob  \\\n",
       "0    run_39       0.408093          209                         0.176   \n",
       "1    run_39       0.408093          209                         0.176   \n",
       "2    run_39       0.408093          209                         0.176   \n",
       "3    run_39       0.408093          209                         0.176   \n",
       "4    run_39       0.408093          209                         0.176   \n",
       "5     run_1       0.253704          407                         0.156   \n",
       "6     run_1       0.253704          407                         0.156   \n",
       "7     run_1       0.253704          407                         0.156   \n",
       "8     run_1       0.253704          407                         0.156   \n",
       "9     run_1       0.253704          407                         0.156   \n",
       "10   run_45       0.062321          384                         0.109   \n",
       "11   run_45       0.062321          384                         0.109   \n",
       "12   run_45       0.062321          384                         0.109   \n",
       "13   run_45       0.062321          384                         0.109   \n",
       "14   run_45       0.062321          384                         0.109   \n",
       "15   run_38       0.316783          126                         0.109   \n",
       "16   run_38       0.316783          126                         0.109   \n",
       "17   run_38       0.316783          126                         0.109   \n",
       "18   run_38       0.316783          126                         0.109   \n",
       "19   run_38       0.316783          126                         0.109   \n",
       "20    run_0       0.082666          264                         0.224   \n",
       "21    run_0       0.082666          264                         0.224   \n",
       "22    run_0       0.082666          264                         0.224   \n",
       "23    run_0       0.082666          264                         0.224   \n",
       "24    run_0       0.082666          264                         0.224   \n",
       "\n",
       "    hidden_dropout_prob  intermediate_size  num_attention_heads  \\\n",
       "0                 0.128               3968                   11   \n",
       "1                 0.128               3968                   11   \n",
       "2                 0.128               3968                   11   \n",
       "3                 0.128               3968                   11   \n",
       "4                 0.128               3968                   11   \n",
       "5                 0.295               9044                   11   \n",
       "6                 0.295               9044                   11   \n",
       "7                 0.295               9044                   11   \n",
       "8                 0.295               9044                   11   \n",
       "9                 0.295               9044                   11   \n",
       "10                0.144                464                   12   \n",
       "11                0.144                464                   12   \n",
       "12                0.144                464                   12   \n",
       "13                0.144                464                   12   \n",
       "14                0.144                464                   12   \n",
       "15                0.279                456                    3   \n",
       "16                0.279                456                    3   \n",
       "17                0.279                456                    3   \n",
       "18                0.279                456                    3   \n",
       "19                0.279                456                    3   \n",
       "20                0.122               4888                    8   \n",
       "21                0.122               4888                    8   \n",
       "22                0.122               4888                    8   \n",
       "23                0.122               4888                    8   \n",
       "24                0.122               4888                    8   \n",
       "\n",
       "    num_hidden_layers  learning_rate  per_device_train_batch_size  ...  \\\n",
       "0                   3       0.000002                           25  ...   \n",
       "1                   3       0.000002                           25  ...   \n",
       "2                   3       0.000002                           25  ...   \n",
       "3                   3       0.000002                           25  ...   \n",
       "4                   3       0.000002                           25  ...   \n",
       "5                   2       0.000005                           25  ...   \n",
       "6                   2       0.000005                           25  ...   \n",
       "7                   2       0.000005                           25  ...   \n",
       "8                   2       0.000005                           25  ...   \n",
       "9                   2       0.000005                           25  ...   \n",
       "10                  3       0.000141                           25  ...   \n",
       "11                  3       0.000141                           25  ...   \n",
       "12                  3       0.000141                           25  ...   \n",
       "13                  3       0.000141                           25  ...   \n",
       "14                  3       0.000141                           25  ...   \n",
       "15                  2       0.000021                           25  ...   \n",
       "16                  2       0.000021                           25  ...   \n",
       "17                  2       0.000021                           25  ...   \n",
       "18                  2       0.000021                           25  ...   \n",
       "19                  2       0.000021                           25  ...   \n",
       "20                  3       0.000396                           25  ...   \n",
       "21                  3       0.000396                           25  ...   \n",
       "22                  3       0.000396                           25  ...   \n",
       "23                  3       0.000396                           25  ...   \n",
       "24                  3       0.000396                           25  ...   \n",
       "\n",
       "   delaney_test_pearsonr  delaney_test_rmse  lipo_valid_pearsonr  \\\n",
       "0               0.887726           0.473826             0.585601   \n",
       "1               0.894136           0.464875             0.595695   \n",
       "2               0.896134           0.462572             0.599250   \n",
       "3               0.894566           0.460415             0.595595   \n",
       "4               0.896773           0.461996             0.592402   \n",
       "5               0.923107           0.410833             0.699566   \n",
       "6               0.921820           0.414782             0.707672   \n",
       "7               0.910316           0.429092             0.702438   \n",
       "8               0.919305           0.418384             0.702826   \n",
       "9               0.914678           0.423083             0.691847   \n",
       "10              0.898042           0.467214             0.825732   \n",
       "11              0.897441           0.468242             0.821326   \n",
       "12              0.900106           0.460513             0.824972   \n",
       "13              0.901569           0.457908             0.822790   \n",
       "14              0.893857           0.469629             0.824558   \n",
       "15              0.859287           0.528923             0.634540   \n",
       "16              0.875391           0.498627             0.636754   \n",
       "17              0.876358           0.496694             0.631261   \n",
       "18              0.851422           0.542233             0.633254   \n",
       "19              0.855497           0.532144             0.632086   \n",
       "20              0.894696           0.461782             0.773668   \n",
       "21              0.894705           0.461380             0.773772   \n",
       "22              0.894023           0.462781             0.761252   \n",
       "23              0.895669           0.458823             0.753817   \n",
       "24              0.895317           0.460283             0.780542   \n",
       "\n",
       "    lipo_valid_rmse  lipo_test_pearsonr  lipo_test_rmse  \\\n",
       "0          0.815095            0.538424        0.778248   \n",
       "1          0.808738            0.558163        0.762622   \n",
       "2          0.806847            0.558706        0.763863   \n",
       "3          0.809195            0.557109        0.765294   \n",
       "4          0.810230            0.543326        0.774747   \n",
       "5          0.731749            0.661364        0.707962   \n",
       "6          0.722468            0.665169        0.701355   \n",
       "7          0.722310            0.637848        0.722440   \n",
       "8          0.727075            0.660596        0.707792   \n",
       "9          0.736963            0.636978        0.729956   \n",
       "10         0.580878            0.781855        0.593911   \n",
       "11         0.587974            0.778362        0.596874   \n",
       "12         0.582189            0.778968        0.595169   \n",
       "13         0.586048            0.782333        0.590521   \n",
       "14         0.585865            0.781918        0.590748   \n",
       "15         0.784420            0.579986        0.773747   \n",
       "16         0.786828            0.587681        0.771717   \n",
       "17         0.785002            0.583220        0.766603   \n",
       "18         0.785299            0.584492        0.768678   \n",
       "19         0.787740            0.582310        0.772713   \n",
       "20         0.648206            0.719486        0.641808   \n",
       "21         0.647530            0.718227        0.642561   \n",
       "22         0.660363            0.704606        0.653160   \n",
       "23         0.671968            0.695670        0.661683   \n",
       "24         0.641785            0.724696        0.639564   \n",
       "\n",
       "    tox21_valid_roc_auc_score  tox21_valid_average_precision_score  \\\n",
       "0                    0.761110                             0.474264   \n",
       "1                    0.754290                             0.447144   \n",
       "2                    0.744852                             0.454886   \n",
       "3                    0.758880                             0.468519   \n",
       "4                    0.759695                             0.478129   \n",
       "5                    0.763856                             0.456702   \n",
       "6                    0.771706                             0.465950   \n",
       "7                    0.765743                             0.463505   \n",
       "8                    0.780585                             0.456097   \n",
       "9                    0.773550                             0.463900   \n",
       "10                   0.767159                             0.469941   \n",
       "11                   0.768531                             0.469811   \n",
       "12                   0.773207                             0.471116   \n",
       "13                   0.765228                             0.465970   \n",
       "14                   0.766386                             0.472628   \n",
       "15                   0.733957                             0.428805   \n",
       "16                   0.747769                             0.444448   \n",
       "17                   0.756949                             0.444470   \n",
       "18                   0.753089                             0.457547   \n",
       "19                   0.747383                             0.454678   \n",
       "20                   0.783030                             0.453764   \n",
       "21                   0.775867                             0.447403   \n",
       "22                   0.781400                             0.453767   \n",
       "23                   0.778955                             0.448230   \n",
       "24                   0.777968                             0.452808   \n",
       "\n",
       "    tox21_test_roc_auc_score  tox21_test_average_precision_score  \n",
       "0                   0.804981                            0.342878  \n",
       "1                   0.799795                            0.345286  \n",
       "2                   0.822888                            0.371321  \n",
       "3                   0.803660                            0.351421  \n",
       "4                   0.792749                            0.356120  \n",
       "5                   0.831450                            0.420656  \n",
       "6                   0.803219                            0.397695  \n",
       "7                   0.821273                            0.406365  \n",
       "8                   0.806546                            0.396876  \n",
       "9                   0.822692                            0.422046  \n",
       "10                  0.743676                            0.366079  \n",
       "11                  0.741621                            0.362950  \n",
       "12                  0.736044                            0.362609  \n",
       "13                  0.745731                            0.364489  \n",
       "14                  0.735114                            0.359081  \n",
       "15                  0.832575                            0.453835  \n",
       "16                  0.827585                            0.446260  \n",
       "17                  0.829101                            0.453295  \n",
       "18                  0.834287                            0.436694  \n",
       "19                  0.833798                            0.459664  \n",
       "20                  0.747493                            0.424763  \n",
       "21                  0.754734                            0.429691  \n",
       "22                  0.741426                            0.429049  \n",
       "23                  0.747444                            0.422272  \n",
       "24                  0.744802                            0.427032  \n",
       "\n",
       "[25 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f2c8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_avg_df.to_csv('ft_results_combined.csv', index=False)\n",
    "combined_all_df.to_csv('ft_results_all_seeds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reverie_env_new] *",
   "language": "python",
   "name": "conda-env-reverie_env_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
